{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.0.0\n"
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "%matplotlib notebook\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF2.Keras MNIST Model \n",
    "\n",
    "> Use conda-enviroment tf2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: ./servable/mnist/1/assets\n"
    }
   ],
   "source": [
    "# Build Model \n",
    "mnist = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3, \n",
    "                      strides=2, activation='relu', name='Conv1'),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
    "])\n",
    "\n",
    "# Export Servable \n",
    "export_mnist_path = './servable/mnist/1/'\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    mnist,\n",
    "    export_mnist_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(mnist, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "test_images = test_images / 255.0\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1) # [B, H, W, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:Layer Conv1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nmnist output shape (1, 10)\nmnist output type <class 'tensorflow.python.framework.ops.EagerTensor'>\nmnist output dtype <dtype: 'float32'>\nmnist input shape (1, 28, 28, 1)\nmnist inpur type <class 'numpy.ndarray'>\nmnist input dtype float64\n"
    }
   ],
   "source": [
    "out = mnist(test_images[:1], training=False)\n",
    "print('mnist output shape', out.shape)\n",
    "print('mnist output type', type(out))\n",
    "print('mnist output dtype', out.dtype)\n",
    "\n",
    "# Input type can be either numpy array / tensor \n",
    "print('mnist input shape', test_images[:1].shape)\n",
    "print('mnist inpur type', type(test_images[:1]))\n",
    "print('mnist input dtype', test_images[:1].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Docker & Servable \n",
    "# See README.md for more informaiton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nMetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n\nsignature_def['__saved_model_init_op']:\n  The given SavedModel SignatureDef contains the following input(s):\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['__saved_model_init_op'] tensor_info:\n        dtype: DT_INVALID\n        shape: unknown_rank\n        name: NoOp\n  Method name is: \n\nsignature_def['serving_default']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['Conv1_input'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 28, 28, 1)\n        name: serving_default_Conv1_input:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['Softmax'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 10)\n        name: StatefulPartitionedCall:0\n  Method name is: tensorflow/serving/predict\n"
    }
   ],
   "source": [
    "# Check saved model for basic info \n",
    "!saved_model_cli show --dir {export_mnist_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "curl: (56) Recv failure: Connection reset by peer\n"
    }
   ],
   "source": [
    "# Check ip:port connection \n",
    "!curl http://localhost:/8501/v1/models/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'{ \"error\": \"Failed to process element: 0 of \\\\\\'instances\\\\\\' list. Error: Invalid argument: JSON Value: 0.0 Type: Number is not of expected type: string\" }'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send request through REST \n",
    "\n",
    "import json\n",
    "import random \n",
    "import requests\n",
    "\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \n",
    "                   \"instances\": test_images[:1].tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "# Without specify model version (use latest)\n",
    "json_response = requests.post('http://localhost:8501/v1/models/mnist:predict', \\\n",
    "                              data=data, headers=headers)\n",
    "\n",
    "json_response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send request through gRPC\n",
    "\n",
    "# pip3 install tensorflow-serving-api\n",
    "\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "import grpc\n",
    "\n",
    "def request_server(img, hostport):\n",
    "    '''\n",
    "    Input:\n",
    "        img [1, H, W, 3] : input image\n",
    "        hostport : tf server port \n",
    "    '''\n",
    "    img = img.astype('float32')\n",
    "    channel = grpc.insecure_channel(hostport)\n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = \"mnist\"\n",
    "    request.model_spec.signature_name = \"serving_default\"  # From signature_def['serving_default']:\n",
    "    request.inputs[\"Conv1_input\"].CopyFrom( # From inputs['Conv1_input'] tensor_info:\n",
    "        tf.make_tensor_proto(img, shape=list(img.shape)))  \n",
    "    response = stub.Predict(request, 5.0)  # 5 secs timeout\n",
    "    return response\n",
    "\n",
    "response = request_server(test_images[:1], '0.0.0.0:8500')\n",
    "print(response.outputs['Softmax']) # From outputs['Softmax'] tensor_info:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF2.Keras Generator Model \n",
    "\n",
    "1. [TF Server RESTful API document](https://www.tensorflow.org/tfx/serving/api_rest)\n",
    "\n",
    "2. [TF Server REST API Example](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model \n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    '''\n",
    "    Input Size: [B, H, W, C]\n",
    "    '''\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    '''\n",
    "    Input Size: [B, H, W, C]\n",
    "    '''\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3]) # (None, 256, 256, 3)\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "        downsample(128, 4), # (bs, 64, 64, 128)\n",
    "        downsample(256, 4), # (bs, 32, 32, 256)\n",
    "        downsample(512, 4), # (bs, 16, 16, 512)\n",
    "        downsample(512, 4), # (bs, 8, 8, 512)\n",
    "        downsample(512, 4), # (bs, 4, 4, 512)\n",
    "        downsample(512, 4), # (bs, 2, 2, 512)\n",
    "        downsample(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4), # (bs, 32, 32, 512)\n",
    "        upsample(128, 4), # (bs, 64, 64, 256)\n",
    "        upsample(64, 4), # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "generator = Generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
    }
   ],
   "source": [
    "# Plot Graph \n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:Assets written to: ./servable/generator/1/assets\n"
    }
   ],
   "source": [
    "# Save Model \n",
    "export_generator_path = './servable/generator/1/'\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    generator,\n",
    "    export_generator_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "input images type <class 'tensorflow.python.framework.ops.EagerTensor'>\ninput images dtype <dtype: 'float32'>\ninput image shape (1, 256, 256, 3)\n"
    }
   ],
   "source": [
    "# Download data from https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz \n",
    "# Unzip data & put data under `./data/facades`\n",
    "\n",
    "# Prepare data \n",
    "def load_img(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    w = tf.shape(image)[1]\n",
    "    w = w // 2\n",
    "    real_image = image[:, :w, :]\n",
    "    input_image = image[:, w:, :]\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)\n",
    "    return input_image, real_image\n",
    "\n",
    "input_img, real_img = load_img('./data/facades/train/100.jpg')\n",
    "\n",
    "# Input of the model can be either numpy array / tensor \n",
    "# input_img = input_img.numpy()\n",
    "\n",
    "print('input images type', type(input_img))\n",
    "print('input images dtype', input_img.dtype)\n",
    "print('input image shape', input_img[tf.newaxis,...].shape)\n",
    "\n",
    "output_img = generator(input_img[tf.newaxis,...], training=False)\n",
    "\n",
    "print('output images type', type(output_img))\n",
    "print('output images dtype', output_img.dtype)\n",
    "print('output image shape', output_img.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(output_img[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('output image range max : {}, min : {}'.format(  np.max(output_img.numpy()), np.min(output_img.numpy())   ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check saved model for basic info \n",
    "!saved_model_cli show --dir {export_generator_path} --all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send request through REST \n",
    "\n",
    "import json\n",
    "import random \n",
    "import requests\n",
    "\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \n",
    "                   \"instances\": input_img[tf.newaxis,...].numpy().tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "# Without specify model version (use latest)\n",
    "json_response = requests.post('http://localhost:8501/v1/models/generator:predict', \\\n",
    "                              data=data, headers=headers)\n",
    "\n",
    "json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_img = json.loads(json_response.text)['predictions']\n",
    "output_img = np.asarray(output_img)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(output_img[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('output image max : {}, min : {}'.format(np.max(output_img), np.min(output_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send request through gRPC\n",
    "\n",
    "def request_server(img, hostport):\n",
    "    '''\n",
    "    Input:\n",
    "        img [1, H, W, 3] : input image\n",
    "        hostport : tf server port \n",
    "    '''\n",
    "    channel = grpc.insecure_channel(hostport)\n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = \"generator\"\n",
    "    request.model_spec.signature_name = \"serving_default\"  \n",
    "    request.inputs[\"input_2\"].CopyFrom(\n",
    "        tf.make_tensor_proto(img, shape=list(img.shape)))  \n",
    "    response = stub.Predict(request, 5.0)  # 5 secs timeout\n",
    "    return response\n",
    "\n",
    "response = request_server(input_img[tf.newaxis,...], '0.0.0.0:8500')\n",
    "output_img = response.outputs['conv2d_transpose_15']\n",
    "output_img = tf.make_ndarray(output_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(output_img[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('output image max : {}, min : {}'.format(np.max(output_img), np.min(output_img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF1.x Session MNIST Servable\n",
    "\n",
    "> Use conda-enviroment tf1\n",
    "> Use conda-enviroment tf2 \n",
    "\n",
    "Save Servable using TF1.x, Test Servable using TF2.x (most model / client we use will be tf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USE TF1 FOR CODE BELOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.0.0\n"
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'predict_pb2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-675aafc77cb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprediction_service_pb2_grpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist_input_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'predict_pb2'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.util import compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reference.serving.tensorflow_serving.example import mnist_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Extracting ./data/mnist/train-images-idx3-ubyte.gz\nExtracting ./data/mnist/train-labels-idx1-ubyte.gz\nExtracting ./data/mnist/t10k-images-idx3-ubyte.gz\nExtracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4f667b3e6b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_input_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/mnist/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mserialized_tf_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input_img'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfeature_configs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFixedLenFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtf_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_tf_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_configs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# Get Data \n",
    "mnist = mnist_input_data.read_data_sets('./data/mnist/', one_hot=True)\n",
    "serialized_tf_example = tf.placeholder(tf.string, name='input_img')\n",
    "feature_configs = {'x': tf.FixedLenFeature(shape=[784], dtype=tf.float32),}\n",
    "tf_example = tf.parse_example(serialized_tf_example, feature_configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.identity(tf_example['x'], name='x') \n",
    "y_ = tf.placeholder('float', shape=[None, 10])\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "y = tf.nn.softmax(tf.matmul(x, w) + b, name='y')\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "values, indices = tf.nn.top_k(y, 10)\n",
    "\n",
    "for _ in range(10):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y_: batch[1]})\n",
    "    #train_step.run(feed_dict={x: batch[0], y_: batch[1]})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "# \n name: \"input_img:0\"\ndtype: DT_STRING\ntensor_shape {\n  unknown_rank: true\n}\n\n# \n name: \"TopKV2:0\"\ndtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: -1\n  }\n  dim {\n    size: 10\n  }\n}\n\n# \n inputs {\n  key: \"inputs\"\n  value {\n    name: \"input_img:0\"\n    dtype: DT_STRING\n    tensor_shape {\n      unknown_rank: true\n    }\n  }\n}\noutputs {\n  key: \"scores\"\n  value {\n    name: \"TopKV2:0\"\n    dtype: DT_FLOAT\n    tensor_shape {\n      dim {\n        size: -1\n      }\n      dim {\n        size: 10\n      }\n    }\n  }\n}\nmethod_name: \"tensorflow/serving/classify\"\n\n"
    }
   ],
   "source": [
    "# Save Model \n",
    "classification_inputs = utils.build_tensor_info(serialized_tf_example)\n",
    "classification_outputs = utils.build_tensor_info(values)\n",
    "print('# \\n',classification_inputs)\n",
    "print('# \\n',classification_outputs)\n",
    "\n",
    "classification_signature = signature_def_utils.build_signature_def(\n",
    "    inputs={signature_constants.CLASSIFY_INPUTS: classification_inputs},\n",
    "    outputs={signature_constants.CLASSIFY_OUTPUT_SCORES:classification_outputs},\n",
    "    method_name=signature_constants.CLASSIFY_METHOD_NAME)\n",
    "print('# \\n',classification_signature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "# \n name: \"x:0\"\ndtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: -1\n  }\n  dim {\n    size: 784\n  }\n}\n\n# \n name: \"y:0\"\ndtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: -1\n  }\n  dim {\n    size: 10\n  }\n}\n\n# \n inputs {\n  key: \"images\"\n  value {\n    name: \"x:0\"\n    dtype: DT_FLOAT\n    tensor_shape {\n      dim {\n        size: -1\n      }\n      dim {\n        size: 784\n      }\n    }\n  }\n}\noutputs {\n  key: \"scores\"\n  value {\n    name: \"y:0\"\n    dtype: DT_FLOAT\n    tensor_shape {\n      dim {\n        size: -1\n      }\n      dim {\n        size: 10\n      }\n    }\n  }\n}\nmethod_name: \"tensorflow/serving/predict\"\n\n"
    }
   ],
   "source": [
    "tensor_info_x = utils.build_tensor_info(x)\n",
    "tensor_info_y = utils.build_tensor_info(y)\n",
    "print('# \\n',tensor_info_x)\n",
    "print('# \\n',tensor_info_y)\n",
    "\n",
    "prediction_signature = signature_def_utils.build_signature_def(\n",
    "      inputs={'images': tensor_info_x},\n",
    "      outputs={'scores': tensor_info_y},\n",
    "      method_name=signature_constants.PREDICT_METHOD_NAME)\n",
    "print('# \\n',prediction_signature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:No assets to save.\nINFO:tensorflow:No assets to write.\nINFO:tensorflow:SavedModel written to: ./servable/mnist/1/saved_model.pb\n"
    },
    {
     "data": {
      "text/plain": "b'./servable/mnist/1/saved_model.pb'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model \n",
    "export_mnist_path = './servable/mnist/1'\n",
    "\n",
    "builder = saved_model_builder.SavedModelBuilder(export_mnist_path)\n",
    "\n",
    "builder.add_meta_graph_and_variables(\n",
    "sess, [tag_constants.SERVING],\n",
    "signature_def_map={\n",
    "    # Q : what's the difference between those 2\n",
    "    'predict_images':prediction_signature,\n",
    "    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:classification_signature,})\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nMetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n\nsignature_def['predict_images']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['images'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 784)\n        name: x:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['scores'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 10)\n        name: y:0\n  Method name is: tensorflow/serving/predict\n\nsignature_def['serving_default']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['inputs'] tensor_info:\n        dtype: DT_STRING\n        shape: unknown_rank\n        name: input_img:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['scores'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 10)\n        name: TopKV2:0\n  Method name is: tensorflow/serving/classify\n"
    }
   ],
   "source": [
    "# Check saved model for basic info \n",
    "!saved_model_cli show --dir {export_mnist_path} --all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USE TF2 FOR CODE BELOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Extracting ./data/mnist/train-images-idx3-ubyte.gz\nExtracting ./data/mnist/train-labels-idx1-ubyte.gz\nExtracting ./data/mnist/t10k-images-idx3-ubyte.gz\nExtracting ./data/mnist/t10k-labels-idx1-ubyte.gz\ninput img shape (1, 784)\ninput img label [7]\n"
    }
   ],
   "source": [
    "# Prepare data \n",
    "test_data_set = mnist_input_data.read_data_sets('./data/mnist/').test\n",
    "input_img, label = test_data_set.next_batch(1) \n",
    "print('input img shape', input_img.shape)\n",
    "print('input img label', label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Extracting ./data/mnist/train-images-idx3-ubyte.gz\nExtracting ./data/mnist/train-labels-idx1-ubyte.gz\nExtracting ./data/mnist/t10k-images-idx3-ubyte.gz\nExtracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
    }
   ],
   "source": [
    "# Send gRPC request \n",
    "import grpc\n",
    "import tensorflow as tf \n",
    "import tensorflow_serving.apis.predict_pb2 as predict_pb2\n",
    "import tensorflow_serving.apis.prediction_service_pb2_grpc as prediction_service_pb2_grpc\n",
    "from reference.serving.tensorflow_serving.example import mnist_input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "request img shape (1, 784)\n"
    },
    {
     "ename": "_Rendezvous",
     "evalue": "<_Rendezvous of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Servable not found for request: Latest(mnist')\"\n\tdebug_error_string = \"{\"created\":\"@1583204832.049054000\",\"description\":\"Error received from peer ipv4:0.0.0.0:8500\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1055,\"grpc_message\":\"Servable not found for request: Latest(mnist')\",\"grpc_status\":5}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_Rendezvous\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-be243f8aa083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0.0.0.0:8500'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#score = response.outputs['scores']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-be243f8aa083>\u001b[0m in \u001b[0;36mrequest_server\u001b[0;34m(img, hostport)\u001b[0m\n\u001b[1;32m     13\u001b[0m     request.inputs[\"images\"].CopyFrom(\n\u001b[1;32m     14\u001b[0m         tf.make_tensor_proto(img, shape=list(img.shape)))  \n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 5 secs timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    688\u001b[0m         state, call, = self._blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    689\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     def with_call(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_Rendezvous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_Rendezvous\u001b[0m: <_Rendezvous of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Servable not found for request: Latest(mnist')\"\n\tdebug_error_string = \"{\"created\":\"@1583204832.049054000\",\"description\":\"Error received from peer ipv4:0.0.0.0:8500\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1055,\"grpc_message\":\"Servable not found for request: Latest(mnist')\",\"grpc_status\":5}\"\n>"
     ]
    }
   ],
   "source": [
    "def request_server(img, hostport):\n",
    "    '''\n",
    "    Input:\n",
    "        img [1, H, W, 3] : input image\n",
    "        hostport : tf server port \n",
    "    '''\n",
    "    channel = grpc.insecure_channel(hostport)\n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = \"mnist'\"\n",
    "    request.model_spec.signature_name = \"predict_images\"  \n",
    "    print('request img shape', img.shape)\n",
    "    request.inputs[\"images\"].CopyFrom(\n",
    "        tf.make_tensor_proto(img, shape=list(img.shape)))  \n",
    "    response = stub.Predict(request, 10.0)  # 5 secs timeout\n",
    "    return response\n",
    "\n",
    "response = request_server(input_img, '0.0.0.0:8500')\n",
    "#score = response.outputs['scores']\n",
    "#score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "output score [[0.02753951 0.00310099 0.00562662 0.01752279 0.01009459 0.02202833\n  0.0062237  0.80996054 0.00724014 0.0906628 ]]\noutput score shape (1, 10)\n"
    }
   ],
   "source": [
    "# Send REST request \n",
    "import json\n",
    "import random \n",
    "import requests\n",
    "import numpy as np \n",
    "\n",
    "data = json.dumps({\"signature_name\": \"predict_images\", \n",
    "                   \"instances\": input_img.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "# Without specify model version (use latest)\n",
    "json_response = requests.post('http://localhost:8501/v1/models/mnist:predict', \\\n",
    "                              data=data, headers=headers)\n",
    "\n",
    "output_scores = json.loads(json_response.text)['predictions']\n",
    "output_scores = np.asarray(output_scores)\n",
    "print('output score', output_scores)\n",
    "print('output score shape', output_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TF1.x Session Complex Style Transfer Servable\n",
    "\n",
    "> Build servable with tf1.x \n",
    "\n",
    "> Test servable with tf2.x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1.12.0\n"
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import json\n",
    "import random \n",
    "import argparse\n",
    "import imageio \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('./reference')\n",
    "sys.path.append('./reference/style_transfer')\n",
    "\n",
    "from reference.style_transfer.model import Artgan\n",
    "from reference.style_transfer.module import * \n",
    "from reference.style_transfer.utils import * \n",
    "\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.util import compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Namespace(gf_dim=32, is_training=False)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--is_training',\n",
    "                    default=False)\n",
    "parser.add_argument('--gf_dim',\n",
    "                    default=32)\n",
    "options = parser.parse_args(args=[])\n",
    "options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sess \n",
    "sess = tf.InteractiveSession()\n",
    "input_photo = tf.placeholder(dtype=tf.float32,shape=[1, None, None, 3],name='input_photo')\n",
    "input_photo_features = encoder(image=input_photo, options=options,reuse=False)\n",
    "output_photo = decoder(features=input_photo_features,options=options,reuse=False)\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "# Activate variables\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:Restoring parameters from ./reference/style_transfer/models/model_morisot/checkpoint_long/model14_morisot_bks10_flw100_135000.ckpt-135000\n"
    }
   ],
   "source": [
    "# Load weight \n",
    "checkpoint_dir = './reference/style_transfer/models/model_morisot/checkpoint_long/'\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "saver.restore(sess, os.path.join(checkpoint_dir, ckpt_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "input_img shape (512, 683, 3)\ninput img type <class 'imageio.core.util.Array'>\n"
    }
   ],
   "source": [
    "# Load imge \n",
    "source_photo_dir =  './reference/style_transfer/data/sample_photographs'\n",
    "source_photo_file = 'Places365_val_00010148.jpg'\n",
    "target_photo_dir =  './reference/style_transfer/data/generated_sample_photographs'\n",
    "target_photo_file = 'generated_Places365_val_00010148.png'\n",
    "\n",
    "if not os.path.exists(target_photo_dir):\n",
    "    os.makedirs(target_photo_dir)\n",
    "\n",
    "input_img = imageio.imread(os.path.join(source_photo_dir, source_photo_file) )\n",
    "print('input_img shape', input_img.shape)\n",
    "print('input img type', type(input_img))\n",
    "\n",
    "input_img = np.expand_dims(input_img, axis=0)\n",
    "# Run Model \n",
    "output_img = sess.run(\n",
    "    output_photo, \n",
    "    feed_dict={\n",
    "        input_photo: normalize_arr_of_imgs(input_img)\n",
    "    }\n",
    ")\n",
    "output_img = denormalize_arr_of_imgs(output_img)\n",
    "output_img = output_img[0]\n",
    "print('output_img shape', output_img.shape)\n",
    "print('output img type', type(output_img))\n",
    "print('output img dtype', output_img.dtype)\n",
    "print('output img range max : {}, min : {} '.format(np.max(output_img), np.min(output_img)))\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(output_img)\n",
    "plt.show()\n",
    "\n",
    "#from PIL import Image \n",
    "#output_img_pil = Image.fromarray(np.uint8(output_img))\n",
    "#output_img_pil.save(os.path.join(target_photo_dir, target_photo_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model \n",
    "tensor_info_input_photo = utils.build_tensor_info(input_photo)\n",
    "tensor_info_output_photo = utils.build_tensor_info(output_photo)\n",
    "\n",
    "generate_signature = signature_def_utils.build_signature_def(\n",
    "      inputs={'input_img': tensor_info_input_photo},\n",
    "      outputs={'output_img': tensor_info_output_photo},\n",
    "      method_name=signature_constants.PREDICT_METHOD_NAME)\n",
    "\n",
    "# Save model \n",
    "export_style_transfer_path = './servable/styletransfer/1'\n",
    "builder = saved_model_builder.SavedModelBuilder(export_style_transfer_path)\n",
    "builder.add_meta_graph_and_variables(\n",
    "    sess, [tag_constants.SERVING],\n",
    "    signature_def_map={'predict_images':generate_signature,}\n",
    "    )\n",
    "builder.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check saved model for basic info \n",
    "!saved_model_cli show --dir {export_style_transfer_path} --all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start TF Server \n",
    "# see `instruction.md` for more information \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:/8500/v1/models/styletransfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "6], [0.348725557, 0.0315257311, -0.804768682], [0.208113074, -0.129586518, -0.696637809], [0.383188248, 0.0416256189, -0.74616313], [0.273474813, -0.157392621, -0.793307304], [0.285830498, -0.093331337, -0.82305783], [0.284296036, -0.0364190936, -0.855494142], [0.321753383, 0.0377722979, -0.782965422], [0.310876846, -0.0151281953, -0.656931937], [0.172788024, -0.16434896, -0.758013666], [0.215035081, -0.0855717659, -0.765595198], [0.191536427, -0.065312922, -0.72579813], [0.392275572, -0.0637449, -0.7364012], [0.315931916, -0.091945231, -0.700961113], [0.0442669392, -0.230433762, -0.737361193], [0.431660533, 0.206907272, -0.629184604], [0.446479559, 0.0192418098, -0.53624928], [0.410989285, -0.0111987591, -0.613794088], [0.443952084, 0.0215506554, -0.667200685], [0.51589787, 0.167890906, -0.507924557], [0.528544188, 0.209535837, -0.5559479], [0.168415904, -0.271309912, -0.727002859], [0.000515937805, -0.207063973, -0.780555129], [0.472940564, 0.236184239, -0.529349566], [0.207671762, -0.220572591, -0.706312954], [0.0246237516, -0.345614016, -0.802059412], [0.159551024, -0.161976039, -0.703616858], [0.257015824, -0.0674448, -0.550161481], [0.150426388, -0.0828924775, -0.545614362], [0.40170753, 0.147157192, -0.478318334], [0.404220939, 0.0334365368, -0.49688071], [-0.270520508, -0.489899874, -0.835235655], [-0.123457491, -0.476361632, -0.902558208], [-0.10677439, -0.493923068, -0.890152693], [-0.572632313, -0.793428421, -0.976503491], [-0.227260888, -0.542131782, -0.929437637], [0.182658553, -0.18699044, -0.698329449], [0.211578727, -0.0987844467, -0.651043296], [0.164758205, -0.19416374, -0.736278296], [0.109287977, -0.166125596, -0.743368268], [0.137405038, -0.363224626, -0.839161098], [-0.300084472, -0.678279519, -0.951827], [-0.187518835, -0.470516503, -0.91905576], [0.566274166, 0.313976645, -0.719922483], [0.368626118, -0.15714252, -0.62385428], [0.197307706, -0.195124447, -0.743432045], [0.259835, -0.189074934, -0.768617272], [0.309401155, -0.126456738, -0.832306], [0.320382476, -0.0757817, -0.857476473], [0.312755585, -0.0803106427, -0.80107367], [0.179560781, -0.218604565, -0.738093], [0.477213502, 0.089938879, -0.686406434], [0.33956182, -0.127639532, -0.683983088], [0.293355942, -0.141354442, -0.773236513], [0.298182249, -0.122741759, -0.758326054], [0.337020874, -0.0407619476, -0.713326454], [0.301079035, -0.0804405808, -0.677948117], [0.181349516, -0.242139637, -0.753116786], [0.213472247, -0.163396358, -0.710632682], [0.106595755, -0.227303088, -0.803029537], [0.244858384, -0.31412065, -0.835713387], [0.169060707, -0.321708024, -0.820947468], [-0.146986008, -0.459324896, -0.887529373], [0.348276377, 0.0594496727, -0.704570651], [0.393592, -0.00857669115, -0.558938742], [0.334097028, -0.0108163357, -0.646387041], [0.317472458, 0.0143294334, -0.612402618], [0.295834064, 0.0308033228, -0.5354684], [0.337406039, 0.0213037729, -0.618157744], [-0.0367485881, -0.34804976, -0.787992656], [-0.138715029, -0.267582536, -0.767995775], [0.424060702, 0.253335476, -0.480970383], [0.370749235, -0.00729960203, -0.445786059], [0.280343771, 0.0183631182, -0.575892687], [0.267354727, 0.0374842882, -0.486068], [0.287394404, 0.058201313, -0.405610681], [0.272160769, 0.0793950558, -0.411775887], [0.414158583, 0.203419566, -0.386483252], [0.43985033, 0.110908985, -0.397373378], [-0.203214407, -0.418886483, -0.785329401], [-0.131921411, -0.43946296, -0.869643867], [0.0255830288, -0.29361552, -0.777896225], [-0.266533494, -0.5712713, -0.897784472], [0.0913105, -0.190882742, -0.752253115], [0.303432584, -0.0666072369, -0.571924269], [0.267891407, -0.00194257498, -0.589823186], [0.176960468, -0.170098245, -0.668825], [0.075427413, -0.201417625, -0.710758924], [0.13094604, -0.318587422, -0.784273088], [-0.0434522629, -0.365069211, -0.820982218], [-0.0318501592, -0.28985846, -0.718356252], [0.414465427, 0.201354384, -0.612223625], [0.347659111, -0.139472663, -0.581584334], [0.257260442, -0.0641601682, -0.660678625], [0.237541795, -0.122760117, -0.663291335], [0.273907542, -0.0160627961, -0.615782857], [0.247454405, -0.0879831314, -0.72881794], [0.130980492, -0.172181487, -0.746093154], [0.0315748453, -0.220252872, -0.684774041], [0.415292978, 0.0963352919, -0.596313834], [0.210477114, -0.196792066, -0.630660951], [0.299656868, -0.129441857, -0.665430546], [0.197116375, -0.119555473, -0.593311846], [0.218251467, -0.0552158356, -0.651458561], [0.171648026, -0.0667079687, -0.703109], [0.269183874, -0.111981332, -0.70141685], [0.0993467569, -0.206569493, -0.711657882], [0.212261081, -0.0651999116, -0.727200866], [0.0086979866, -0.366442919, -0.799282849], [-0.019818604, -0.466240346, -0.868724465], [-0.0823408961, -0.353020668, -0.855294347], [0.446326971, 0.143525839, -0.629993677], [0.297445416, -0.0275472403, -0.553247], [0.349496961, -0.133962572, -0.628585696], [0.229752302, -0.130791664, -0.701270282], [0.228724241, -0.0181447268, -0.537892759], [0.128698945, 0.0303528309, -0.654943228], [-0.0548017621, -0.492122948, -0.85145539], [-0.298985779, -0.48759234, -0.839218557], [0.325184226, 0.165489316, -0.538581252], [-0.0408463478, -0.509757161, -0.650120497], [-0.12962395, -0.546402216, -0.846695185], [-0.0132168531, -0.368473291, -0.797605395], [0.126633644, -0.235431612, -0.563960671], [0.0394006968, -0.133883357, -0.474871457], [0.294893742, 0.108410835, -0.354432762], [0.354781389, -0.0102276206, -0.507515073], [-0.669218063, -0.82393074, -0.95012337], [-0.572969437, -0.72506249, -0.980486333], [-0.212532759, -0.540649533, -0.8913095], [-0.614125848, -0.80898416, -0.969040811], [-0.516071439, -0.756225824, -0.953555942], [-0.398761928, -0.644397, -0.895762086], [-0.315694273, -0.542426229, -0.847936809], [-0.298177779, -0.59768188, -0.892243862], [-0.370241165, -0.570841789, -0.837473392], [-0.152277768, -0.438607931, -0.833056927], [-0.304677486, -0.578044534, -0.866724], [-0.236772597, -0.44817853, -0.764790535], [0.478370667, 0.205075145, -0.528927207], [0.30600071, -0.184617817, -0.51525], [0.165286779, -0.171469092, -0.651665], [0.21864903, -0.227208555, -0.671348], [0.0926137, -0.260149, -0.759350538], [0.0811928511, -0.317903101, -0.875535786], [-0.139521599, -0.452216983, -0.903342128], [-0.197056472, -0.494637132, -0.86836952], [0.326516271, -0.00737303495, -0.725728273], [0.149163246, -0.31872493, -0.648851454], [0.283876181, -0.204734683, -0.703630507], [0.197850943, -0.210087597, -0.607264638], [0.200384736, -0.165628195, -0.710913062], [0.199817181, -0.102932215, -0.723312], [0.280821085, -0.184853375, -0.723551273], [0.235318065, -0.175521314, -0.682280183], [0.299670815, -0.00167971849, -0.701828241], [0.209292531, -0.396669209, -0.767282248], [0.0932400227, -0.482022762, -0.860379934], [0.0423295498, -0.346785903, -0.847054362], [0.489367843, 0.181105614, -0.607723892], [0.443826318, -0.0221521258, -0.489157796], [0.301847458, -0.0593163967, -0.663328707], [0.293385148, -0.0525172949, -0.616368175], [0.315031171, 0.100625873, -0.562006235], [0.336464643, -0.0325830579, -0.67407], [-0.0620356798, -0.416328073, -0.841408074], [-0.237547457, -0.41549623, -0.851197839], [0.428642154, 0.25946188, -0.589703918], [0.223670959, -0.235379517, -0.54679215], [0.121620178, -0.252483, -0.728839636], [0.137636423, -0.178682566, -0.632413864], [0.273171663, -0.0753855705, -0.482734203], [0.161694407, -0.0165661573, -0.458459139], [0.43606782, 0.225688815, -0.367922306], [0.480262041, 0.137274027, -0.409594], [-0.401613712, -0.575886786, -0.854392529], [-0.198223293, -0.480547607, -0.904199839], [0.0733015537, -0.243861496, -0.791694283], [-0.543039918, -0.757925451, -0.961180806], [-0.254358947, -0.487775624, -0.915159464], [0.264399409, -0.0941871405, -0.61262989], [0.27142942, -0.0694797039, -0.609541655], [0.0158480406, -0.347317338, -0.783674955], [-0.0927276, -0.357916534, -0.757338881], [0.0695735216, -0.467340887, -0.830536902], [-0.403293, -0.769262671, -0.934893548], [-0.276952386, -0.54091543, -0.861897349], [0.669886, 0.40128839, -0.522584796], [0.507832646, -0.163287699, -0.460970223], [0.370468497, -0.104321, -0.64895153], [0.300109863, -0.228145, -0.604908347], [0.311874509, -0.110517025, -0.643234], [0.320817, -0.0726729631, -0.645781], [0.314573765, -0.0276212096, -0.655500054], [0.190367222, -0.135733187, -0.641803145], [0.307881713, 0.0373712778, -0.624683857], [0.28838551, -0.11994642, -0.594218791], [0.236466527, -0.157687426, -0.664788604], [0.312952638, -0.022868216, -0.616960287], [0.273131251, 0.104964375, -0.612672567], [0.183266759, -0.041372478, -0.590314746], [-0.103349745, -0.371509731, -0.729052603], [-0.121364236, -0.274984896, -0.782173157], [-0.18143034, -0.383496284, -0.830610633], [-0.0554093719, -0.485193253, -0.85986042], [-0.0668048263, -0.49835062, -0.810827911], [-0.348618209, -0.558563471, -0.809205472], [0.338934064, 0.0626115799, -0.681634068], [0.418861032, -0.121253431, -0.528550625], [0.402437449, -0.0381169319, -0.62937361], [0.329763651, -0.0275124907, -0.548063159], [0.407312393, 0.148671627, -0.444206], [0.429520249, 0.183678269, -0.460867], [0.139955521, -0.180242896, -0.677502632], [-0.0688790679, -0.253604472, -0.762816489], [0.265258908, 0.00966155529, -0.592969894], [0.10952878, -0.161943555, -0.583155632], [0.207351685, -0.0220354795, -0.548723578], [0.298941493, 0.0748122931, -0.44666636], [0.296028137, 0.0337557793, -0.397166729], [0.315827727, 0.167289376, -0.359987736], [0.450999379, 0.314795852, -0.239752233], [0.53390038, 0.244371057, -0.346425056], [-0.526204, -0.65025115, -0.88720417], [-0.443712711, -0.598320544, -0.960243821], [-0.217778206, -0.463504076, -0.896042764], [-0.626814723, -0.773416936, -0.969007075], [-0.0880548358, -0.352911234, -0.895784259], [0.150697351, -0.253073454, -0.612898707], [0.0549823046, -0.209121764, -0.702930927], [-0.0108424425, -0.30664295, -0.71224165], [-0.0679197311, -0.277299702, -0.773515821], [-0.0431340933, -0.427624047, -0.901445], [-0.461045504, -0.726713657, -0.968396306], [-0.373729646, -0.553724885, -0.92966038], [0.466692686, 0.236613393, -0.749805629], [0.244624376, -0.352788866, -0.601545751], [0.308007598, -0.29293251, -0.80979073], [0.232685208, -0.306835592, -0.840771735], [0.369469404, -0.117205799, -0.713051319], [0.288988113, -0.0606849194, -0.596188307], [0.238233924, -0.0533382893, -0.648434699], [0.298315406, -0.0147138834, -0.638553739], [0.313395858, 0.125976324, -0.60718286], [0.308329582, -0.114610374, -0.711280763], [-0.0243045688, -0.323780954, -0.841235757], [-0.0928221941, -0.298499465, -0.848121881], [0.390362144, 0.238332152, -0.680537462], [0.338411331, -0.00935024, -0.508388519], [0.249291778, 0.0129538774, -0.683087468], [0.219923139, -0.0201123953, -0.608253241], [0.312374353, 0.0804771185, -0.539020896], [0.339515448, 0.130061984, -0.516551554], [0.368221879, 0.124828458, -0.538609385], [0.377429247, 0.0592200756, -0.514633179], [0.00213813782, -0.207131803, -0.725884438], [0.0094383955, -0.323884606, -0.836606801], [-0.0456626415, -0.284178495, -0.819200099], [-0.26730758, -0.512785077, -0.901296258], [0.078715086, -0.152872443, -0.793066382], [0.234703779, -0.0898852348, -0.574910879], [0.177902818, -0.0346319675, -0.593893051], [0.015104413, -0.236383379, -0.713043928], [-0.120919883, -0.335165203, -0.814695835], [-0.0621798635, -0.511793792, -0.861234784], [-0.285744548, -0.602723479, -0.903705359], [-0.190060139, -0.495624483, -0.846493959], [0.522022247, 0.25965, -0.6807971], [0.499709845, -0.081964314, -0.41487664], [0.39274466, 0.0356731415, -0.620718122], [0.362365961, -0.0607596636, -0.581880093], [0.337660551, 0.0195958614, -0.606874466], [0.33789289, 0.0212849379, -0.605486512], [0.360683799, 0.01676929, -0.6187464], [0.37183702, 0.0284342766, -0.60292685], [0.366703629, 0.113605142, -0.594994187], [0.426777959, 0.0201604366, -0.584529281], [0.341998219, 0.0550268888, -0.551475286], [0.384421825, 0.110999942, -0.545059919], [0.404615641, 0.28546381, -0.584631443], [0.348951221, -0.00985634327, -0.566294789], [-0.155892551, -0.376396716, -0.746759117], [0.0503996611, -0.156710088, -0.719755054], [0.0930347443, -0.124538064, -0.651210904], [0.207884908, -0.0868353844, -0.724920809], [-0.00848424435, -0.293254256, -0.713624775], [-0.279890716, -0.358288407, -0.775072], [0.35041976, 0.100094676, -0.559482872], [0.231445789, -0.00875228643, -0.562792778], [0.00914084911, -0.23841995, -0.766297758], [0.0355340242, -0.262754321, -0.805814326], [0.0494201183, -0.185149252, -0.713301301], [0.155454636, 0.0314278603, -0.673898578], [0.111626029, -0.0980635285, -0.722924292], [0.121099472, -0.151875019, -0.683611393], [0.296119571, 0.0825028419, -0.567717433], [0.230690122, -0.00159555674, -0.535710335], [0.398277402, 0.203131795, -0.433155596], [0.350570202, 0.105543375, -0.438153923], [0.265838027, 0.0205087662, -0.499020517], [0.301852, 0.0593386889, -0.46894896], [0.244723558, 0.0546799898, -0.564641476], [0.128304482, -0.116948843, -0.720691919], [-0.265192628, -0.398790956, -0.834159434], [-0.184015989, -0.427741826, -0.855525494], [-0.208052576, -0.358758807, -0.821650326], [-0.456980944, -0.616881669, -0.872153759], [0.099301219, -0.112445652, -0.709975719], [0.256545186, -0.0498752, -0.406933844], [0.203958392, 0.0446304083, -0.598165393], [0.0940073729, -0.154488981, -0.625074863], [0.0720785856, -0.155302763, -0.675062299], [0.0507092476, -0.284828067, -0.806923211], [-0.289518654, -0.54264009, -0.914512694], [-0.229345739, -0.448357344, -0.831670761], [0.532170653, 0.326731801, -0.469130695], [0.231197476, -0.16008997, -0.50180757], [0.339398384, -0.105609536, -0.698967338], [0.28252387, -0.148006201, -0.654739261], [0.288201213, -0.0330969691, -0.650194526], [0.226085663, -0.116193, -0.653387904], [0.234995246, -0.0997207165, -0.689654827], [0.277867436, -0.0689700246, -0.6661852], [0.351073265, 0.120936275, -0.592818677], [0.422849417, 0.0207294226, -0.627194285], [0.233843446, -0.176536322, -0.725651503], [0.0740599632, -0.171877563, -0.761459708], [0.440694213, 0.300834537, -0.615500033], [0.292209506, -0.103714943, -0.60380733], [0.064520359, -0.299980044, -0.793411076], [0.232719898, -0.116018414, -0.824507535], [0.257477403, -0.0689867735, -0.644694924], [0.380176544, 0.13698256, -0.58937937], [0.185243487, -0.0657737851, -0.70070219], [0.0388127565, -0.125300825, -0.767383635], [0.250083685, -0.105933249, -0.693386793], [0.0331368446, -0.304740906, -0.866133809], [-0.0453065038, -0.452213526, -0.91707015], [-0.143309355, -0.48160392, -0.962696433], [-0.107725322, -0.474454224, -0.924765348], [0.008441329, -0.200234771, -0.852466702], [0.345475078, 0.0209736824, -0.712760329], [0.363315821, 0.0183979273, -0.648557186], [0.342800975, 0.094558, -0.613861203], [0.25295639, -0.051448524, -0.642808735], [0.376918197, 0.157986045, -0.510341108], [0.290456414, 0.0582106113, -0.602713346], [0.256159663, 0.0247740746, -0.681994081], [0.201246619, -0.0454363227, -0.646741271], [0.0762826204, -0.07590729, -0.741194725], [0.116899967, -0.142871499, -0.797674239], [-0.339029372, -0.448465168, -0.902450919], [-0.297416568, -0.507682, -0.934370399], [-0.27369529, -0.460856795, -0.890373528], [-0.412550509, -0.570168614, -0.901219547], [0.0716209412, -0.172311187, -0.774883926], [0.0329227448, -0.306013882, -0.579187751], [0.0549029112, -0.144706726, -0.667422295], [0.00834929943, -0.231131017, -0.647037327], [-0.0766484737, -0.29087925, -0.770225585], [-0.205497026, -0.365544021, -0.878521621], [-0.413413346, -0.627718329, -0.918705285], [-0.248333514, -0.412415206, -0.799433351], [0.396762729, 0.214322567, -0.524594128], [0.0912351608, -0.225194335, -0.561517775], [0.281415, -0.165190101, -0.643308282], [0.174219251, -0.144056559, -0.632608414], [0.288042784, 0.00058734417, -0.590059757], [0.235233307, -0.0873375535, -0.541303873], [0.145932078, -0.0897574425, -0.600089669], [0.201069832, -0.0759397149, -0.630201817], [0.279057384, 0.0534808636, -0.525601745], [0.322824478, -0.000839948654, -0.563252807], [0.125443459, -0.203766108, -0.695306778], [-0.0886644125, -0.240169525, -0.718829155], [0.443076611, 0.301804066, -0.546892405], [0.179171562, -0.233351111, -0.552048445], [-0.059576869, -0.354911149, -0.796715319], [0.0425354242, -0.218966901, -0.767896533], [0.172126651, -0.0888444781, -0.548303127], [0.197290421, 0.0211664438, -0.516707897], [0.137981534, 0.00886762142, -0.582998276], [0.0724066496, -0.0337260365, -0.65055716], [-0.135672927, -0.364432931, -0.750782967], [-0.315523028, -0.514477789, -0.89483279], [-0.377980471, -0.60835278, -0.913723648], [-0.60526824, -0.747095704, -0.978531718], [-0.337214351, -0.509198427, -0.920555592], [0.00507521629, -0.200123549, -0.692228258], [0.307798743, 0.0973399878, -0.573656201], [0.305665016, 0.0566078424, -0.548344612], [0.101774335, -0.0533874035, -0.630718708], [0.0750309229, -0.127187848, -0.651831627], [0.220794797, 0.0566416979, -0.47348094], [0.1640172, 0.0204082727, -0.558960438], [0.284022808, 0.116757631, -0.529003799], [0.254134774, 0.0925329924, -0.54565227], [0.0336776972, -0.100398242, -0.720207632], [0.149798512, -0.116768837, -0.787253], [-0.36106503, -0.438190043, -0.913376], [-0.341989458, -0.475690365, -0.952359557], [-0.423526525, -0.57185775, -0.935502589], [-0.50857687, -0.679854393, -0.949782729], [-0.0482491851, -0.298686981, -0.852003932], [0.042314291, -0.360900283, -0.656243145], [0.198817492, -0.0717746615, -0.644224763], [0.0602827072, -0.165085852, -0.61953342], [0.00640797615, -0.202673137, -0.723217487], [-0.0185617208, -0.249004483, -0.828859806], [-0.22557205, -0.540301681, -0.888162255], [-0.0811548233, -0.278301656, -0.776795208], [0.391436934, 0.208345294, -0.568727493], [-0.000441133976, -0.485613942, -0.693010211], [0.030077219, -0.516761422, -0.879635811], [-0.090328753, -0.458993733, -0.948546231], [0.349487543, -0.00381344557, -0.768669665], [0.30196, -0.0435305834, -0.463088393], [0.132975101, -0.0826767087, -0.667161882], [0.172998667, -0.061409235, -0.658935189], [0.110872865, -0.0132734776, -0.603881955], [0.2077595, -0.0121722221, -0.714990735], [-0.216189861, -0.428196251, -0.871387959], [-0.288358808, -0.370826364, -0.866770267], [0.417781353, 0.323810577, -0.624347806], [0.0389966965, -0.279895365, -0.572683692], [-0.214379132, -0.444878459, -0.879833281], [-0.0446434021, -0.321437836, -0.883661568], [0.150733232, -0.148799419, -0.652107835], [0.150935888, 0.0193097591, -0.559355855], [0.289078236, 0.104346514, -0.584587693], [0.314358473, 0.0633113384, -0.543622673], [-0.121403813, -0.270582855, -0.769977629], [-0.12120223, -0.378193438, -0.914045274], [-0.266329765, -0.43395555, -0.922523439], [-0.53605932, -0.639316678, -0.970935464], [-0.173467577, -0.368831694, -0.916710913], [-0.0345399976, -0.257737458, -0.794348359], [-0.00939703, -0.100240052, -0.747227669], [0.0335606337, -0.189167857, -0.780278683], [-0.180777609, -0.325323701, -0.82463], [-0.152013361, -0.453011036, -0.870337605], [-0.355668068, -0.632217407, -0.936451852], [-0.269582629, -0.496534348, -0.928838253], [0.498874903, 0.149783731, -0.761732], [0.266792178, -0.259461, -0.541314], [0.403079271, -0.156235576, -0.71087], [0.267447591, -0.353993, -0.913880467], [0.246434927, -0.385932088, -0.942253411], [0.309963346, -0.0770947337, -0.797353625], [0.366009, -0.0377318859, -0.773695111], [0.321195841, -0.0465812683, -0.695513725], [0.417995811, 0.149496198, -0.627721488], [0.437028766, 0.126922965, -0.70185709], [0.232193232, -0.114905953, -0.810956657], [0.0960519314, -0.205299795, -0.845981777], [0.414991617, 0.0923081636, -0.752148], [0.233913064, -0.0940315127, -0.670869231], [0.229413986, -0.0895726085, -0.725832939], [0.220674038, -0.0552712083, -0.673359156], [0.176293373, -0.135514617, -0.658962846], [0.191252112, -0.0952789187, -0.720671356], [-0.0153663754, -0.304633021, -0.799622357], [0.156525016, -0.0856773853, -0.707132816], [0.24210608, 0.1237396, -0.630364895], [0.205589056, -0.110817254, -0.716957688], [-0.201548457, -0.318258524, -0.866602242], [-0.280712, -0.523772597, -0.918477654]]]\\n    ]\\n}'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send RESTful request \n",
    "import json\n",
    "import random \n",
    "import requests\n",
    "import numpy as np \n",
    "\n",
    "data = json.dumps({\"signature_name\": \"predict_images\", \n",
    "                   \"instances\": input_img.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "# Without specify model version (use latest)\n",
    "json_response = requests.post('http://localhost:8501/v1/models/styletransfer:predict', \\\n",
    "                              data=data, headers=headers)\n",
    "\n",
    "json_response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_img = json.loads(json_response.text)['predictions']\n",
    "output_img = np.asarray(output_img)\n",
    "output_img = output_img[0]\n",
    "output_img = denormalize_arr_of_imgs(output_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('output_img shape', output_img.shape)\n",
    "print('output img type', type(output_img))\n",
    "print('output img dtype', output_img.dtype)\n",
    "print('output img range max : {}, min : {} '.format(np.max(output_img), np.min(output_img)))\n",
    "\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(output_img)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python361064bittf2conda2a839d36a2d44dfe952fd3d58afbe64c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}