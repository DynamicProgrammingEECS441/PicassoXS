{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.0.0\n"
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF2.Keras MNIST Model \n",
    "\n",
    "> Use conda-enviroment tf2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:Assets written to: ./servable/mnist/1/assets\n"
    }
   ],
   "source": [
    "# Build Model \n",
    "mnist = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3, \n",
    "                      strides=2, activation='relu', name='Conv1'),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
    "])\n",
    "\n",
    "# Export Servable \n",
    "export_mnist_path = './servable/mnist/1/'\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    mnist,\n",
    "    export_mnist_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dd6a9a0b6edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(mnist, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "test_images = test_images / 255.0\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1) # [B, H, W, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mnist(test_images[:1], training=False)\n",
    "print('mnist output shape', out.shape)\n",
    "print('mnist output type', type(out))\n",
    "print('mnist output dtype', out.dtype)\n",
    "\n",
    "# Input type can be either numpy array / tensor \n",
    "print('mnist input shape', test_images[:1].shape)\n",
    "print('mnist inpur type', type(test_images[:1]))\n",
    "print('mnist input dtype', test_images[:1].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Start Docker & Servable \n",
    "# See README.md for more informaiton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Traceback (most recent call last):\n  File \"/opt/anaconda3/envs/tf2/bin/saved_model_cli\", line 11, in <module>\n    sys.exit(main())\n  File \"/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/tools/saved_model_cli.py\", line 909, in main\n    args.func(args)\n  File \"/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/tools/saved_model_cli.py\", line 610, in show\n    _show_all(args.dir)\n  File \"/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/tools/saved_model_cli.py\", line 192, in _show_all\n    tag_sets = saved_model_utils.get_saved_model_tag_sets(saved_model_dir)\n  File \"/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/tools/saved_model_utils.py\", line 88, in get_saved_model_tag_sets\n    saved_model = read_saved_model(saved_model_dir)\n  File \"/opt/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/tools/saved_model_utils.py\", line 55, in read_saved_model\n    raise IOError(\"SavedModel file does not exist at: %s\" % saved_model_dir)\nOSError: SavedModel file does not exist at: {export_mnist_path}\n"
    }
   ],
   "source": [
    "# Check saved model for basic info \n",
    "!saved_model_cli show --dir {export_mnist_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "curl: (56) Recv failure: Connection reset by peer\n"
    }
   ],
   "source": [
    "# Check ip:port connection \n",
    "!curl http://localhost:/8501/v1/models/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'{ \"error\": \"Failed to process element: 0 of \\\\\\'instances\\\\\\' list. Error: Invalid argument: JSON Value: 0.0 Type: Number is not of expected type: string\" }'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send request through REST \n",
    "\n",
    "import json\n",
    "import random \n",
    "import requests\n",
    "\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \n",
    "                   \"instances\": test_images[:1].tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "# Without specify model version (use latest)\n",
    "json_response = requests.post('http://localhost:8501/v1/models/mnist:predict', \\\n",
    "                              data=data, headers=headers)\n",
    "\n",
    "json_response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send request through gRPC\n",
    "\n",
    "# pip3 install tensorflow-serving-api\n",
    "\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "import grpc\n",
    "\n",
    "def request_server(img, hostport):\n",
    "    '''\n",
    "    Input:\n",
    "        img [1, H, W, 3] : input image\n",
    "        hostport : tf server port \n",
    "    '''\n",
    "    img = img.astype('float32')\n",
    "    channel = grpc.insecure_channel(hostport)\n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = \"mnist\"\n",
    "    request.model_spec.signature_name = \"serving_default\"  # From signature_def['serving_default']:\n",
    "    request.inputs[\"Conv1_input\"].CopyFrom( # From inputs['Conv1_input'] tensor_info:\n",
    "        tf.make_tensor_proto(img, shape=list(img.shape)))  \n",
    "    response = stub.Predict(request, 5.0)  # 5 secs timeout\n",
    "    return response\n",
    "\n",
    "response = request_server(test_images[:1], '0.0.0.0:8500')\n",
    "print(response.outputs['Softmax']) # From outputs['Softmax'] tensor_info:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF2.Keras Generator Model \n",
    "\n",
    "1. [TF Server RESTful API document](https://www.tensorflow.org/tfx/serving/api_rest)\n",
    "\n",
    "2. [TF Server REST API Example](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model \n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    '''\n",
    "    Input Size: [B, H, W, C]\n",
    "    '''\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    '''\n",
    "    Input Size: [B, H, W, C]\n",
    "    '''\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3]) # (None, 256, 256, 3)\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "        downsample(128, 4), # (bs, 64, 64, 128)\n",
    "        downsample(256, 4), # (bs, 32, 32, 256)\n",
    "        downsample(512, 4), # (bs, 16, 16, 512)\n",
    "        downsample(512, 4), # (bs, 8, 8, 512)\n",
    "        downsample(512, 4), # (bs, 4, 4, 512)\n",
    "        downsample(512, 4), # (bs, 2, 2, 512)\n",
    "        downsample(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4), # (bs, 32, 32, 512)\n",
    "        upsample(128, 4), # (bs, 64, 64, 256)\n",
    "        upsample(64, 4), # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "generator = Generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
    }
   ],
   "source": [
    "# Plot Graph \n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:Assets written to: ./servable/generator/1/assets\n"
    }
   ],
   "source": [
    "# Save Model \n",
    "export_generator_path = './servable/generator/1/'\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    generator,\n",
    "    export_generator_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "input images type <class 'tensorflow.python.framework.ops.EagerTensor'>\ninput images dtype <dtype: 'float32'>\ninput image shape (1, 256, 256, 3)\n"
    }
   ],
   "source": [
    "# Download data from https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz \n",
    "# Unzip data & put data under `./data/facades`\n",
    "\n",
    "# Prepare data \n",
    "def load_img(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    w = tf.shape(image)[1]\n",
    "    w = w // 2\n",
    "    real_image = image[:, :w, :]\n",
    "    input_image = image[:, w:, :]\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)\n",
    "    return input_image, real_image\n",
    "\n",
    "input_img, real_img = load_img('./data/facades/train/100.jpg')\n",
    "\n",
    "# Input of the model can be either numpy array / tensor \n",
    "# input_img = input_img.numpy()\n",
    "\n",
    "print('input images type', type(input_img))\n",
    "print('input images dtype', input_img.dtype)\n",
    "print('input image shape', input_img[tf.newaxis,...].shape)\n",
    "\n",
    "output_img = generator(input_img[tf.newaxis,...], training=False)\n",
    "\n",
    "print('output images type', type(output_img))\n",
    "print('output images dtype', output_img.dtype)\n",
    "print('output image shape', output_img.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(output_img[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('output image range max : {}, min : {}'.format(  np.max(output_img.numpy()), np.min(output_img.numpy())   ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nMetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n\nsignature_def['__saved_model_init_op']:\n  The given SavedModel SignatureDef contains the following input(s):\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['__saved_model_init_op'] tensor_info:\n        dtype: DT_INVALID\n        shape: unknown_rank\n        name: NoOp\n  Method name is: \n\nsignature_def['serving_default']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['input_1'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 256, 256, 3)\n        name: serving_default_input_1:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['conv2d_transpose_7'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 256, 256, 3)\n        name: StatefulPartitionedCall:0\n  Method name is: tensorflow/serving/predict\n"
    }
   ],
   "source": [
    "# Check saved model for basic info \n",
    "!saved_model_cli show --dir {export_generator_path} --all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send request through REST \n",
    "\n",
    "import json\n",
    "import random \n",
    "import requests\n",
    "\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \n",
    "                   \"instances\": input_img[tf.newaxis,...].numpy().tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "# Without specify model version (use latest)\n",
    "json_response = requests.post('http://localhost:8501/v1/models/generator:predict', \\\n",
    "                              data=data, headers=headers)\n",
    "\n",
    "json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_img = json.loads(json_response.text)['predictions']\n",
    "output_img = np.asarray(output_img)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(output_img[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('output image max : {}, min : {}'.format(np.max(output_img), np.min(output_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send request through gRPC\n",
    "\n",
    "def request_server(img, hostport):\n",
    "    '''\n",
    "    Input:\n",
    "        img [1, H, W, 3] : input image\n",
    "        hostport : tf server port \n",
    "    '''\n",
    "    channel = grpc.insecure_channel(hostport)\n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = \"generator\"\n",
    "    request.model_spec.signature_name = \"serving_default\"  \n",
    "    request.inputs[\"input_2\"].CopyFrom(\n",
    "        tf.make_tensor_proto(img, shape=list(img.shape)))  \n",
    "    response = stub.Predict(request, 5.0)  # 5 secs timeout\n",
    "    return response\n",
    "\n",
    "response = request_server(input_img[tf.newaxis,...], '0.0.0.0:8500')\n",
    "output_img = response.outputs['conv2d_transpose_15']\n",
    "output_img = tf.make_ndarray(output_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(output_img[0])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('output image max : {}, min : {}'.format(np.max(output_img), np.min(output_img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF1.x Session MNIST Servable\n",
    "\n",
    "> Use conda-enviroment tf1\n",
    "> Use conda-enviroment tf2 \n",
    "\n",
    "Save Servable using TF1.x, Test Servable using TF2.x (most model / client we use will be tf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USE TF1 FOR CODE BELOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.0.0\n"
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'predict_pb2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-675aafc77cb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprediction_service_pb2_grpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist_input_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'predict_pb2'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.util import compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reference.serving.tensorflow_serving.example import mnist_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Extracting ./data/mnist/train-images-idx3-ubyte.gz\nExtracting ./data/mnist/train-labels-idx1-ubyte.gz\nExtracting ./data/mnist/t10k-images-idx3-ubyte.gz\nExtracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4f667b3e6b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_input_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/mnist/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mserialized_tf_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input_img'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfeature_configs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFixedLenFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtf_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_tf_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_configs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# Get Data \n",
    "mnist = mnist_input_data.read_data_sets('./data/mnist/', one_hot=True)\n",
    "serialized_tf_example = tf.placeholder(tf.string, name='input_img')\n",
    "feature_configs = {'x': tf.FixedLenFeature(shape=[784], dtype=tf.float32),}\n",
    "tf_example = tf.parse_example(serialized_tf_example, feature_configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.identity(tf_example['x'], name='x') \n",
    "y_ = tf.placeholder('float', shape=[None, 10])\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "y = tf.nn.softmax(tf.matmul(x, w) + b, name='y')\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "values, indices = tf.nn.top_k(y, 10)\n",
    "\n",
    "for _ in range(10):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y_: batch[1]})\n",
    "    #train_step.run(feed_dict={x: batch[0], y_: batch[1]})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "# \n name: \"input_img:0\"\ndtype: DT_STRING\ntensor_shape {\n  unknown_rank: true\n}\n\n# \n name: \"TopKV2:0\"\ndtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: -1\n  }\n  dim {\n    size: 10\n  }\n}\n\n# \n inputs {\n  key: \"inputs\"\n  value {\n    name: \"input_img:0\"\n    dtype: DT_STRING\n    tensor_shape {\n      unknown_rank: true\n    }\n  }\n}\noutputs {\n  key: \"scores\"\n  value {\n    name: \"TopKV2:0\"\n    dtype: DT_FLOAT\n    tensor_shape {\n      dim {\n        size: -1\n      }\n      dim {\n        size: 10\n      }\n    }\n  }\n}\nmethod_name: \"tensorflow/serving/classify\"\n\n"
    }
   ],
   "source": [
    "# Save Model \n",
    "classification_inputs = utils.build_tensor_info(serialized_tf_example)\n",
    "classification_outputs = utils.build_tensor_info(values)\n",
    "print('# \\n',classification_inputs)\n",
    "print('# \\n',classification_outputs)\n",
    "\n",
    "classification_signature = signature_def_utils.build_signature_def(\n",
    "    inputs={signature_constants.CLASSIFY_INPUTS: classification_inputs},\n",
    "    outputs={signature_constants.CLASSIFY_OUTPUT_SCORES:classification_outputs},\n",
    "    method_name=signature_constants.CLASSIFY_METHOD_NAME)\n",
    "print('# \\n',classification_signature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "# \n name: \"x:0\"\ndtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: -1\n  }\n  dim {\n    size: 784\n  }\n}\n\n# \n name: \"y:0\"\ndtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: -1\n  }\n  dim {\n    size: 10\n  }\n}\n\n# \n inputs {\n  key: \"images\"\n  value {\n    name: \"x:0\"\n    dtype: DT_FLOAT\n    tensor_shape {\n      dim {\n        size: -1\n      }\n      dim {\n        size: 784\n      }\n    }\n  }\n}\noutputs {\n  key: \"scores\"\n  value {\n    name: \"y:0\"\n    dtype: DT_FLOAT\n    tensor_shape {\n      dim {\n        size: -1\n      }\n      dim {\n        size: 10\n      }\n    }\n  }\n}\nmethod_name: \"tensorflow/serving/predict\"\n\n"
    }
   ],
   "source": [
    "tensor_info_x = utils.build_tensor_info(x)\n",
    "tensor_info_y = utils.build_tensor_info(y)\n",
    "print('# \\n',tensor_info_x)\n",
    "print('# \\n',tensor_info_y)\n",
    "\n",
    "prediction_signature = signature_def_utils.build_signature_def(\n",
    "      inputs={'images': tensor_info_x},\n",
    "      outputs={'scores': tensor_info_y},\n",
    "      method_name=signature_constants.PREDICT_METHOD_NAME)\n",
    "print('# \\n',prediction_signature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:No assets to save.\nINFO:tensorflow:No assets to write.\nINFO:tensorflow:SavedModel written to: ./servable/mnist/1/saved_model.pb\n"
    },
    {
     "data": {
      "text/plain": "b'./servable/mnist/1/saved_model.pb'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model \n",
    "export_mnist_path = './servable/mnist/1'\n",
    "\n",
    "builder = saved_model_builder.SavedModelBuilder(export_mnist_path)\n",
    "\n",
    "builder.add_meta_graph_and_variables(\n",
    "sess, [tag_constants.SERVING],\n",
    "signature_def_map={\n",
    "    # Q : what's the difference between those 2\n",
    "    'predict_images':prediction_signature,\n",
    "    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:classification_signature,})\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nMetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n\nsignature_def['predict_images']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['images'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 784)\n        name: x:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['scores'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 10)\n        name: y:0\n  Method name is: tensorflow/serving/predict\n\nsignature_def['serving_default']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['inputs'] tensor_info:\n        dtype: DT_STRING\n        shape: unknown_rank\n        name: input_img:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['scores'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 10)\n        name: TopKV2:0\n  Method name is: tensorflow/serving/classify\n"
    }
   ],
   "source": [
    "# Check saved model for basic info \n",
    "!saved_model_cli show --dir {export_mnist_path} --all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USE TF2 FOR CODE BELOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Extracting ./data/mnist/train-images-idx3-ubyte.gz\nExtracting ./data/mnist/train-labels-idx1-ubyte.gz\nExtracting ./data/mnist/t10k-images-idx3-ubyte.gz\nExtracting ./data/mnist/t10k-labels-idx1-ubyte.gz\ninput img shape (1, 784)\ninput img label [7]\n"
    }
   ],
   "source": [
    "# Prepare data \n",
    "test_data_set = mnist_input_data.read_data_sets('./data/mnist/').test\n",
    "input_img, label = test_data_set.next_batch(1) \n",
    "print('input img shape', input_img.shape)\n",
    "print('input img label', label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Extracting ./data/mnist/train-images-idx3-ubyte.gz\nExtracting ./data/mnist/train-labels-idx1-ubyte.gz\nExtracting ./data/mnist/t10k-images-idx3-ubyte.gz\nExtracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
    }
   ],
   "source": [
    "# Send gRPC request \n",
    "import grpc\n",
    "import tensorflow as tf \n",
    "import tensorflow_serving.apis.predict_pb2 as predict_pb2\n",
    "import tensorflow_serving.apis.prediction_service_pb2_grpc as prediction_service_pb2_grpc\n",
    "from reference.serving.tensorflow_serving.example import mnist_input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "request img shape (1, 784)\n"
    },
    {
     "ename": "_Rendezvous",
     "evalue": "<_Rendezvous of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Servable not found for request: Latest(mnist')\"\n\tdebug_error_string = \"{\"created\":\"@1583204832.049054000\",\"description\":\"Error received from peer ipv4:0.0.0.0:8500\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1055,\"grpc_message\":\"Servable not found for request: Latest(mnist')\",\"grpc_status\":5}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_Rendezvous\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-be243f8aa083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'0.0.0.0:8500'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#score = response.outputs['scores']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-be243f8aa083>\u001b[0m in \u001b[0;36mrequest_server\u001b[0;34m(img, hostport)\u001b[0m\n\u001b[1;32m     13\u001b[0m     request.inputs[\"images\"].CopyFrom(\n\u001b[1;32m     14\u001b[0m         tf.make_tensor_proto(img, shape=list(img.shape)))  \n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 5 secs timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    688\u001b[0m         state, call, = self._blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    689\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     def with_call(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_Rendezvous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_Rendezvous\u001b[0m: <_Rendezvous of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Servable not found for request: Latest(mnist')\"\n\tdebug_error_string = \"{\"created\":\"@1583204832.049054000\",\"description\":\"Error received from peer ipv4:0.0.0.0:8500\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1055,\"grpc_message\":\"Servable not found for request: Latest(mnist')\",\"grpc_status\":5}\"\n>"
     ]
    }
   ],
   "source": [
    "def request_server(img, hostport):\n",
    "    '''\n",
    "    Input:\n",
    "        img [1, H, W, 3] : input image\n",
    "        hostport : tf server port \n",
    "    '''\n",
    "    channel = grpc.insecure_channel(hostport)\n",
    "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "    request = predict_pb2.PredictRequest()\n",
    "    request.model_spec.name = \"mnist'\"\n",
    "    request.model_spec.signature_name = \"predict_images\"  \n",
    "    print('request img shape', img.shape)\n",
    "    request.inputs[\"images\"].CopyFrom(\n",
    "        tf.make_tensor_proto(img, shape=list(img.shape)))  \n",
    "    response = stub.Predict(request, 10.0)  # 5 secs timeout\n",
    "    return response\n",
    "\n",
    "response = request_server(input_img, '0.0.0.0:8500')\n",
    "#score = response.outputs['scores']\n",
    "#score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "output score [[0.02753951 0.00310099 0.00562662 0.01752279 0.01009459 0.02202833\n  0.0062237  0.80996054 0.00724014 0.0906628 ]]\noutput score shape (1, 10)\n"
    }
   ],
   "source": [
    "# Send REST request \n",
    "import json\n",
    "import random \n",
    "import requests\n",
    "import numpy as np \n",
    "\n",
    "data = json.dumps({\"signature_name\": \"predict_images\", \n",
    "                   \"instances\": input_img.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "# Without specify model version (use latest)\n",
    "json_response = requests.post('http://localhost:8501/v1/models/mnist:predict', \\\n",
    "                              data=data, headers=headers)\n",
    "\n",
    "output_scores = json.loads(json_response.text)['predictions']\n",
    "output_scores = np.asarray(output_scores)\n",
    "print('output score', output_scores)\n",
    "print('output score shape', output_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TF1.x Session Complex Style Transfer Servable\n",
    "\n",
    "> Build servable with tf1.x \n",
    "\n",
    "> Test servable with tf2.x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1.12.0\n"
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import json\n",
    "import random \n",
    "import argparse\n",
    "import imageio \n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('./reference')\n",
    "sys.path.append('./reference/style_transfer')\n",
    "\n",
    "from reference.style_transfer.model import Artgan\n",
    "from reference.style_transfer.module import * \n",
    "from reference.style_transfer.utils import * \n",
    "\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.util import compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Namespace(gf_dim=32, is_training=False)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--is_training',\n",
    "                    default=False)\n",
    "parser.add_argument('--gf_dim',\n",
    "                    default=32)\n",
    "options = parser.parse_args(args=[])\n",
    "options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sess \n",
    "sess = tf.InteractiveSession()\n",
    "input_photo = tf.placeholder(dtype=tf.float32,shape=[1, None, None, 3],name='input_photo')\n",
    "input_photo_features = encoder(image=input_photo, options=options,reuse=False)\n",
    "output_photo = decoder(features=input_photo_features,options=options,reuse=False)\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "# Activate variables\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weight \n",
    "checkpoint_dir = './reference/style_transfer/models/model_morisot/checkpoint_long/'\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "saver.restore(sess, os.path.join(checkpoint_dir, ckpt_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load imge \n",
    "source_photo_dir =  './reference/style_transfer/data/sample_photographs'\n",
    "source_photo_file = 'Places365_val_00010148.jpg'\n",
    "target_photo_dir =  './reference/style_transfer/data/generated_sample_photographs'\n",
    "target_photo_file = 'generated_Places365_val_00010148.png'\n",
    "\n",
    "if not os.path.exists(target_photo_dir):\n",
    "    os.makedirs(target_photo_dir)\n",
    "\n",
    "input_img = imageio.imread(os.path.join(source_photo_dir, source_photo_file) )\n",
    "print('input_img shape', input_img.shape)\n",
    "print('input img type', type(input_img))\n",
    "\n",
    "input_img = np.expand_dims(input_img, axis=0)\n",
    "# Run Model \n",
    "output_img = sess.run(\n",
    "    output_photo, \n",
    "    feed_dict={\n",
    "        input_photo: normalize_arr_of_imgs(input_img)\n",
    "    }\n",
    ")\n",
    "output_img = denormalize_arr_of_imgs(output_img)\n",
    "output_img = output_img[0]\n",
    "print('output_img shape', output_img.shape)\n",
    "print('output img type', type(output_img))\n",
    "print('output img dtype', output_img.dtype)\n",
    "print('output img range max : {}, min : {} '.format(np.max(output_img), np.min(output_img)))\n",
    "\n",
    "from PIL import Image \n",
    "output_img_pil = Image.fromarray(np.uint8(output_img))\n",
    "output_img_pil.save(os.path.join(target_photo_dir, target_photo_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model \n",
    "tensor_info_input_photo = utils.build_tensor_info(input_photo)\n",
    "tensor_info_output_photo = utils.build_tensor_info(output_photo)\n",
    "\n",
    "generate_signature = signature_def_utils.build_signature_def(\n",
    "      inputs={'input_img': tensor_info_input_photo},\n",
    "      outputs={'output_img': tensor_info_output_photo},\n",
    "      method_name=signature_constants.PREDICT_METHOD_NAME)\n",
    "\n",
    "# Save model \n",
    "export_style_transfer_path = './servable/styletransfer/1'\n",
    "builder = saved_model_builder.SavedModelBuilder(export_style_transfer_path)\n",
    "builder.add_meta_graph_and_variables(\n",
    "    sess, [tag_constants.SERVING],\n",
    "    signature_def_map={'predict_images':generate_signature,}\n",
    "    )\n",
    "builder.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check saved model for basic info \n",
    "!saved_model_cli show --dir {export_style_transfer_path} --all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start TF Server \n",
    "# see `instruction.md` for more information \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:/8500/v1/models/styletransfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send RESTful request \n",
    "import json\n",
    "import random \n",
    "import requests\n",
    "import numpy as np \n",
    "\n",
    "data = json.dumps({\"signature_name\": \"predict_images\", \n",
    "                   \"input_img\": input_img.tolist()})\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "# Without specify model version (use latest)\n",
    "json_response = requests.post('http://localhost:8501/v1/models/styletransfer:predict', \\\n",
    "                              data=data, headers=headers)\n",
    "\n",
    "output_img = json.loads(json_response.text)['output_img']\n",
    "output_img = np.asarray(output_img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tf1': conda)",
   "language": "python",
   "name": "python361064bittf1conda15b10e4330584cdca11675dc7fdbd620"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}